---
title: "LangChain in Real-World Apps"
publishedAt: "2025-11-04"
summary: "How to practically implement LangChain to build intelligent, agent-powered applications."
---

# LangChain Guide for JavaScript/TypeScript üöÄ

LangChain is a powerful framework for building applications powered by large language models. It lets you compose context-aware, multi-step chains of prompts, LLM calls, tools, and memory to create smart apps.

## Installation \& Setup üõ†Ô∏è

To start, install LangChain via npm:

```
npm install langchain @langchain/core
```

Then import the modules you need:

import { ChatOpenAI } from "@langchain/openai";
const model = new ChatOpenAI({ temperature: 0.7 });
const result = await model.invoke("Hello!");
console.log(result);

## Core Components

LangChain's core modules include **Prompts**, **LLMs**, **Chains**, **Agents**, and **Memory**.

### Prompts üìã

Prompt templates help format instructions to the LLM:
```
import { ChatPromptTemplate } from "@langchain/core/prompts";
const prompt = ChatPromptTemplate.fromTemplate("Make up a joke about {topic}");
text
```

### LLMs ü§ñ

LangChain provides interfaces to many LLM providers:
```
import { ChatOpenAI } from "@langchain/openai";
const model = new ChatOpenAI({ model: "gpt-4", temperature: 0.5 });
const result = await model.invoke("Say something nice!");
console.log(result);
```

### Chains üîó

A Chain sequences operations:
```
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";
const prompt = ChatPromptTemplate.fromTemplate("Make up a {adjective} joke.");
const model = new ChatOpenAI();
const chain = prompt.pipe(model);
const result = await chain.invoke({ adjective: "spooky" });
console.log(result);
```

### Agents ‚ö°

Agents let the model call tools automatically. Think of an agent as a reasoning loop: it queries the LLM for what to do, executes a tool, then loops until a final answer.
```
import { initializeAgent } from "@langchain/agents";
const tools = [wikiTool, calcTool];
const agent = await initializeAgent(model, tools);
const answer = await agent.call({ input: "What's 13 factorial?" });
console.log(answer);
```

### Memory üß†

Memory lets your app remember past interactions:
```
import { ChatOpenAI } from "@langchain/openai";
import { BufferMemory } from "@langchain/memory";
import { ConversationChain } from "@langchain/chains";
const model = new ChatOpenAI();
const memory = new BufferMemory();
const conversation = new ConversationChain({ llm: model, memory });
const res1 = await conversation.call({ input: "Hi! I'm Jim." });
console.log(res1.response);
const res2 = await conversation.call({ input: "What's my name?" });
console.log(res2.response);
```

## When to Use What ü§î

- **Simple LLM calls:** Use a Prompt + LLM when you just need to ask the model something directly.
- **Structured workflows:** Use Chains when you have a fixed sequence.
- **Tool-using workflows:** Use Agents when the model should decide what tools to invoke.
- **Chatbots:** Use ConversationChain with BufferMemory to hold history.
- **Retrieval/Q\&A:** Use a vector store plus retriever to fetch relevant docs.


## Pros \& Cons üìàüìâ

**Advantages:**

- Modular and Composable
- TypeScript Support
- Lots of Integrations
- Cross-Environment Support
- Active Development

**Disadvantages:**

- Documentation sometimes lags behind Python version
- Type Safety can be tricky
- Overhead for simple use cases
- LLM limitations and hallucinations


## Summary

LangChain is a powerful framework for building AI apps. Start simple with just prompts and models, then gradually add chains, agents, and memory as needed. Keep learning and experimenting!

Bilkul bhai! Yeh lo **COMPLETE aur 100% CORRECT MDX file** - bas copy-paste kar de:

```mdx
---
title: "LangChain in Real-World Apps"
publishedAt: "2025-11-04"
summary: "How to practically implement LangChain to build intelligent, agent-powered applications."
---

# LangChain Guide for JavaScript/TypeScript üöÄ

LangChain is a powerful framework for building applications powered by large language models. It lets you compose context-aware, multi-step chains of prompts, LLM calls, tools, and memory to create smart apps.

## Installation & Setup üõ†Ô∏è

To start, install LangChain via npm:

```
`
npm install langchain @langchain/core
`
```
Then import the modules you need:
```

```
import { ChatOpenAI } from "@langchain/openai";

const model = new ChatOpenAI({ temperature: 0.7 });
const result = await model.invoke("Hello!");
console.log(result);
```

```
## Core Components

LangChain's core modules include **Prompts**, **LLMs**, **Chains**, **Agents**, and **Memory**.

### Prompts üìã

Prompt templates help format instructions to the LLM:

import { ChatPromptTemplate } from "@langchain/core/prompts";

const prompt = ChatPromptTemplate.fromTemplate("Make up a joke about {topic}");

```

### LLMs ü§ñ

LangChain provides interfaces to many LLM providers:

```

import { ChatOpenAI } from "@langchain/openai";

const model = new ChatOpenAI({ model: "gpt-4", temperature: 0.5 });
const result = await model.invoke("Say something nice!");
console.log(result);

```

### Chains üîó

A Chain sequences operations:

```

import { ChatPromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";

const prompt = ChatPromptTemplate.fromTemplate("Make up a {adjective} joke.");
const model = new ChatOpenAI();
const chain = prompt.pipe(model);
const result = await chain.invoke({ adjective: "spooky" });
console.log(result);

```

### Agents ‚ö°

Agents let the model call tools automatically. Think of an agent as a reasoning loop: it queries the LLM for what to do, executes a tool, then loops until a final answer.

```

import { initializeAgent } from "@langchain/agents";

const tools = [wikiTool, calcTool];
const agent = await initializeAgent(model, tools);
const answer = await agent.call({ input: "What's 13 factorial?" });
console.log(answer);

```

### Memory üß†

Memory lets your app remember past interactions:

```

import { ChatOpenAI } from "@langchain/openai";
import { BufferMemory } from "@langchain/memory";
import { ConversationChain } from "@langchain/chains";

const model = new ChatOpenAI();
const memory = new BufferMemory();
const conversation = new ConversationChain({ llm: model, memory });

const res1 = await conversation.call({ input: "Hi! I'm Jim." });
console.log(res1.response);

const res2 = await conversation.call({ input: "What's my name?" });
console.log(res2.response);

```

## When to Use What ü§î

- **Simple LLM calls:** Use a Prompt + LLM when you just need to ask the model something directly.
- **Structured workflows:** Use Chains when you have a fixed sequence.
- **Tool-using workflows:** Use Agents when the model should decide what tools to invoke.
- **Chatbots:** Use ConversationChain with BufferMemory to hold history.
- **Retrieval/Q&A:** Use a vector store plus retriever to fetch relevant docs.

## Pros & Cons üìàüìâ

**Advantages:**

- Modular and Composable
- TypeScript Support
- Lots of Integrations
- Cross-Environment Support
- Active Development

**Disadvantages:**

- Documentation sometimes lags behind Python version
- Type Safety can be tricky
- Overhead for simple use cases
- LLM limitations and hallucinations

## Summary

LangChain is a powerful framework for building AI apps. Start simple with just prompts and models, then gradually add chains, agents, and memory as needed. Keep learning and experimenting!
```